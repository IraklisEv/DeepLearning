{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 0. Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#In order to acquire the dataset in a Cloud VM environment\n","\n","'''\n","from google.cloud import storage\n","\n","bucket_name = \"isic-bucket\"\n","\n","storage_client = storage.Client()\n","bucket = storage_client.get_bucket(bucket_name)\n","\n","my_prefix = \"Training/\" # the name of the subfolder\n","blobs = bucket.list_blobs(prefix = my_prefix, delimiter = '/')\n","\n","for blob in blobs:\n","    if(blob.name != my_prefix): # ignoring the subfolder itself \n","        file_name = blob.name.replace(my_prefix, \"\")\n","        blob.download_to_filename(file_name) # download the file to the machine\n","\n","import zipfile\n","with zipfile.ZipFile('./Dataset.zip', 'r') as zip_ref:\n","    zip_ref.extractall('./lol')\n","        '''"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import itertools\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","#from glob import glob\n","#import seaborn as sns\n","from PIL import Image\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","import keras\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","from keras import backend as K\n","from keras.optimizers import Adam, RMSprop\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","#from keras.layers.normalization import BatchNormalization\n","from keras.applications.resnet50 import ResNet50\n","from keras.applications.vgg19 import VGG19\n","from keras import backend as K \n"]},{"cell_type":"markdown","metadata":{"_uuid":"c170def1ed6bd1e279dc6d5ae86a95cf6cfd2efb"},"source":["# 1. Acquiring the training data"]},{"cell_type":"markdown","metadata":{},"source":["## 1.1 Loading - splitting the data"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["8388\n","1113\n"]}],"source":["import PIL\n","train_folder = './Training'\n","valid_folder = './Validation'\n","\n","train_data = pd.read_csv(train_folder + '/' + 'ISIC2018_Training_GroundTruth.csv')\n","valid_data = pd.read_csv(valid_folder + '/' + 'ISIC2018_Validation_GroundTruth.csv')\n","\n","malignant = train_data.loc[(train_data['MEL'] == 1)| (train_data['BCC'] == 1)]\n","benign = train_data.loc[(train_data['MEL'] == 0) & (train_data['BCC'] == 0)]\n","\n","print(len(benign))\n","print(len(malignant))\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def load_images(load_dir, image_list):\n","    lst = [np.asarray(Image.open(load_dir + '/' + filename + '.jpg').convert('RGB')) for filename in image_list]\n","    return lst"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def load_prepare_dataset(dataset_csv, folder):\n","\n","    malignant = dataset_csv.loc[dataset_csv['MEL'] == 1]\n","    benign = dataset_csv.loc[dataset_csv['MEL'] == 0]\n","    # Load in training pictures \n","    benign_images = load_images(folder, benign['image'])\n","    malignant_images = load_images(folder, malignant['image'])\n","    print(f'len malignant:{len(malignant)}')\n","    print(f'len benign:{len(benign)}')\n","    X_benign = np.array(benign_images, dtype='uint8')\n","    X_malignant = np.array(malignant_images, dtype='uint8')\n","\n","    # Create labels\n","    y_benign = np.zeros(X_benign.shape[0])\n","    y_malignant = np.ones(X_malignant.shape[0])\n","\n","    # Merge data \n","    x = np.concatenate((X_benign, X_malignant), axis = 0)\n","    y = np.concatenate((y_benign, y_malignant), axis = 0)\n","\n","    # Shuffle data\n","    s = np.arange(x.shape[0])\n","    np.random.shuffle(s)\n","    x = x[s]\n","    y = y[s]\n","\n","    y = to_categorical(y, num_classes= 2)\n","    x = x/255.\n","\n","    return x, y\n","    "]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["len malignant:5\n","len benign:35\n"]}],"source":["#train_folder = './small'\n","#benign = benign['image'].iloc[:40]\n","#malignant = malignant['image'].iloc[:40]\n","\n","X_train, y_train = load_prepare_dataset(train_data.loc, train_folder)"]},{"cell_type":"markdown","metadata":{},"source":["## 1.2 Data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_datagen = ImageDataGenerator(rescale=(1/255.),shear_range = 0.2,zoom_range=0.2,\n","                                   horizontal_flip=True)\n","training_set = train_datagen.flow_from_directory(directory = train_dir,target_size=(64,64),\n","                                                batch_size=32,\n","                                                class_mode = \"binary\")\n","test_datagen = ImageDataGenerator(rescale=(1/255.))\n","test_set = test_datagen.flow_from_directory(directory = test_dir,target_size=(64,64),\n","                                                batch_size=32,\n","                                                class_mode = \"binary\")"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Data visualisation and exploration (work in progress)"]},{"cell_type":"markdown","metadata":{},"source":["## 2.1 Data exploration"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["\"w=40\\nh=30\\nfig=plt.figure(figsize=(12, 8))\\ncolumns = 5\\nrows = 3\\n\\nfor i in range(1, columns*rows +1):\\n    ax = fig.add_subplot(rows, columns, i)\\n    if (y_train[i] == np.asarray([1,0])).all():\\n        ax.title.set_text('Benign')\\n    else:\\n        ax.title.set_text('Malignant')\\n    plt.imshow(X_train[i], interpolation='nearest')\\nplt.show()\""]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["'''w=40\n","h=30\n","fig=plt.figure(figsize=(12, 8))\n","columns = 5\n","rows = 3\n","\n","for i in range(1, columns*rows +1):\n","    ax = fig.add_subplot(rows, columns, i)\n","    if (y_train[i] == np.asarray([1,0])).all():\n","        ax.title.set_text('Benign')\n","    else:\n","        ax.title.set_text('Malignant')\n","    plt.imshow(X_train[i], interpolation='nearest')\n","plt.show()'''"]},{"cell_type":"markdown","metadata":{},"source":["## 2.2 Data visualisation"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#Missing graphs for presentation"]},{"cell_type":"markdown","metadata":{"_uuid":"857f705a561f046a1d63ffa17a8a0b1e8da16ff5"},"source":["# 3. Building the models \n","## 3.1 Necessary functions"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def run_model(model):\n","    history = model.fit(X_train, y_train, validation_split=0.2,\n","                        epochs= epochs, batch_size= batch_size, verbose=0, \n","                        callbacks=[learning_rate_reduction]\n","                    )\n","                    \n","    # list all data in history\n","    print(history.history.keys())\n","    # summarize history for accuracy\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","    # summarize history for loss\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_model(input_shape= (224,224,3), lr = 1e-3, num_classes= 2, init= 'normal', activ= 'relu', optim= 'adam'):\n","    \n","    model = Sequential()\n","    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same',input_shape=input_shape,\n","                     activation= activ, kernel_initializer='glorot_uniform'))\n","    model.add(MaxPool2D(pool_size = (2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same', \n","                     activation =activ, kernel_initializer = 'glorot_uniform'))\n","    model.add(MaxPool2D(pool_size = (2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu', kernel_initializer=init))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.summary()\n","\n","    if optim == 'rmsprop':\n","        optimizer = RMSprop(lr=lr)\n","\n","    else:\n","        optimizer = Adam(lr=lr)\n","\n","    model.compile(optimizer = optimizer ,loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n","    return model\n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["def save_model(model, model_filename):\n","    model_json = model.to_json()\n","\n","    with open(model_filename + \".json\", \"w\") as json_file:\n","        json_file.write(model_json)\n","        \n","    model.save_weights(model_filename + \".h5\")\n","    print(\"Saved\")\n","\n","    del model\n","    K.clear_session()"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Custom CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_shape = (224,224,3)\n","lr = 1e-5\n","init = 'normal'\n","activ = 'relu'\n","optim = 'adam' # <-----NEEDS TO CHANGE\n","epochs = 50\n","batch_size = 64\n","\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                            patience=5, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=1e-7)\n","\n","cnn_model = build_model(lr=lr, init= init, activ= activ, optim=optim, input_shape= input_shape)\n","run_model(cnn_model)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1.1 Cross-validation"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"55083e7f7d76cb7131b655701021ba2745627c43","trusted":true},"outputs":[],"source":["kfold = KFold(n_splits=3, shuffle=True, random_state=17)\n","\n","cvscores = []\n","for train, test in kfold.split(X_train, y_train):\n","    model = build_model(lr=lr, \n","                  init= init, \n","                  activ= activ, \n","                  optim=optim, \n","                  input_shape= input_shape)\n","    \n","    model.fit(X_train[train], y_train[train], epochs=epochs, batch_size=batch_size, verbose=0)\n","    scores = model.evaluate(X_train[test], y_train[test], verbose=0)\n","    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","    cvscores.append(scores[1] * 100)\n","    K.clear_session()\n","    del model\n","    \n","print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1.2 Testing"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["X_test, y_test = load_prepare_dataset(valid_data, valid_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = build_model(lr=lr, \n","              init= init, \n","              activ= activ, \n","              optim=optim, \n","              input_shape= input_shape)\n","\n","model.fit(X_train, y_train,\n","          epochs=epochs, batch_size= batch_size, verbose=0,\n","          callbacks=[learning_rate_reduction]\n","         )\n","\n","y_pred = model.predict_classes(X_test)\n","\n","print(accuracy_score(np.argmax(y_test, axis=1),y_pred))\n","\n","save_model(model, 'cnn_model')"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 ResNet50\n","### 3.2.1 Building the model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_shape = (224,224,3)\n","lr = 1e-5\n","epochs = 50\n","batch_size = 64\n","\n","model = ResNet50(include_top=True,\n","                 weights= None,\n","                 input_tensor=None,\n","                 input_shape=input_shape,\n","                 pooling='avg',\n","                 classes=2)\n","\n","\n","run_model(model)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2.2 Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.fit(X_train, y_train,\n","          epochs=epochs, batch_size= epochs, verbose=0,\n","          callbacks=[learning_rate_reduction]\n","         )\n","\n","y_pred = model.predict(X_test)\n","\n","print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n","\n","save_model(model, 'resnet_model')"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 VGG19"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_shape = (224,224,3)\n","lr = 1e-5\n","epochs = 10\n","batch_size = 256\n","\n","\n","vgg19_model = VGG16(include_top=False,\n","                 weights= 'imagenet',\n","                 input_tensor=None,\n","                 input_shape=input_shape,\n","                 pooling='avg',\n","                 classes=2)\n","\n","for layer in vgg19_model.layers:\n","    layer.trainable = False\n","    \n","model = Sequential()\n","model.add(vgg19_model)\n","model.add(Flatten())\n","model.add(Dense(512, activation = 'relu'))\n","model.add(Dropout(0.25))\n","model.add(Dense(2, activation='softmax'))\n","\n","run_model(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(X_train, y_train,\n","          epochs=epochs, batch_size= epochs, verbose=0,\n","          callbacks=[learning_rate_reduction]\n","         )\n","\n","y_pred = model.predict(X_test)\n","\n","print(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n","\n","save_model(model, 'vgg_model')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
